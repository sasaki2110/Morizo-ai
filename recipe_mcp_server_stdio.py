#!/usr/bin/env python3
"""
Morizo AI - Recipe MCP Server
Copyright (c) 2024 Morizo AI Project. All rights reserved.

This software is proprietary and confidential. Unauthorized copying, modification,
distribution, or use is strictly prohibited without explicit written permission.

For licensing inquiries, contact: [contact@morizo-ai.com]

Recipe MCP Server (stdio transport)
ãƒ¬ã‚·ãƒ”ææ¡ˆæ©Ÿèƒ½ç”¨ã®MCPã‚µãƒ¼ãƒãƒ¼ï¼ˆã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–¹å¼ã€stdioæ¥ç¶šï¼‰
"""

import os
import json
import logging
import asyncio
from datetime import datetime
from typing import Dict, Any, List, Optional
from fastmcp import FastMCP
from pydantic import BaseModel
from dotenv import load_dotenv
from openai import AsyncOpenAI

# LangChainé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆRAGæ¤œç´¢ç”¨ï¼‰
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# Perplexity APIé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.perplexity_client import PerplexityAPIClient, RecipeSearchResult

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# FastMCPãƒ­ã‚´ã‚’éè¡¨ç¤ºã«ã™ã‚‹ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ï¼‰
os.environ["FASTMCP_DISABLE_BANNER"] = "1"

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# MCPã‚µãƒ¼ãƒãƒ¼ã®åˆæœŸåŒ–
mcp = FastMCP("Recipe Suggestion Server")

class OpenAIClient:
    """OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY must be set in .env")
        self._client: Optional[AsyncOpenAI] = None

    def get_client(self) -> AsyncOpenAI:
        if self._client is None:
            self._client = AsyncOpenAI(api_key=self.api_key)
        return self._client

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
openai_client = OpenAIClient()

class RecipeVectorSearch:
    """ãƒ¬ã‚·ãƒ”ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, vector_db_path: str):
        """
        åˆæœŸåŒ–
        
        Args:
            vector_db_path: ãƒ™ã‚¯ãƒˆãƒ«DBã®ãƒ‘ã‚¹
        """
        self.vector_db_path = vector_db_path
        self.vectorstore = None
        self.embeddings = None
        
    def _load_vector_db(self):
        """ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã‚€"""
        try:
            logger.info(f"ãƒ™ã‚¯ãƒˆãƒ«DBèª­ã¿è¾¼ã¿ä¸­: {self.vector_db_path}")
            
            # OpenAI Embeddingsã®åˆæœŸåŒ–
            self.embeddings = OpenAIEmbeddings()
            
            # ChromaDBãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’èª­ã¿è¾¼ã¿
            self.vectorstore = Chroma(
                persist_directory=self.vector_db_path,
                embedding_function=self.embeddings
            )
            
            logger.info("ãƒ™ã‚¯ãƒˆãƒ«DBèª­ã¿è¾¼ã¿å®Œäº†")
            
        except Exception as e:
            logger.error(f"ãƒ™ã‚¯ãƒˆãƒ«DBèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def search_similar_recipes(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        é¡ä¼¼ãƒ¬ã‚·ãƒ”ã‚’æ¤œç´¢
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: å–å¾—ã™ã‚‹ä»¶æ•°
            
        Returns:
            æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        """
        try:
            if self.vectorstore is None:
                self._load_vector_db()
            
            logger.info(f"ãƒ¬ã‚·ãƒ”æ¤œç´¢: '{query}' (ä¸Šä½{k}ä»¶)")
            
            # é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            
            # çµæœã‚’æ•´å½¢
            formatted_results = []
            for i, (doc, score) in enumerate(results, 1):
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
                metadata = doc.metadata
                
                # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¬ã‚·ãƒ”ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡ºï¼ˆæœ€åˆã®è¡Œã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã™ã‚‹ï¼‰
                text_lines = doc.page_content.split('\n')
                title = text_lines[0] if text_lines else "Unknown"
                
                formatted_result = {
                    "rank": i,
                    "title": title,
                    "category": metadata.get("recipe_category", "ä¸æ˜"),
                    "main_ingredients": metadata.get("main_ingredients", ""),
                    "similarity_score": round(score, 4),
                    "text_preview": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                }
                formatted_results.append(formatted_result)
            
            logger.info(f"æ¤œç´¢çµæœ: {len(formatted_results)}ä»¶")
            return formatted_results
            
        except Exception as e:
            logger.error(f"ãƒ¬ã‚·ãƒ”æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            raise

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
vector_search = None
perplexity_client = None

def get_vector_search():
    """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
    global vector_search
    if vector_search is None:
        vector_db_path = "/app/Morizo-ai/recipe_vector_db"
        vector_search = RecipeVectorSearch(vector_db_path)
    return vector_search

def get_perplexity_client():
    """Perplexity API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
    global perplexity_client
    if perplexity_client is None:
        perplexity_client = PerplexityAPIClient()
    return perplexity_client

# Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
class MenuPlan(BaseModel):
    main_dish: Dict[str, Any]
    side_dish: Dict[str, Any]
    soup: Dict[str, Any]
    excluded_recipes: List[str] = []

# é£Ÿæåˆ†é¡é–¢æ•°ã‚’å‰Šé™¤ï¼ˆAIãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ä¸è¦ï¼‰

# get_recent_recipesé–¢æ•°ã‚’å‰Šé™¤ï¼ˆç–çµåˆè¨­è¨ˆã§ã¯å¤–éƒ¨ã‹ã‚‰å—ã‘å–ã‚‹ï¼‰

async def generate_menu_with_llm(
    inventory_items: List[str],
    menu_type: str,
    excluded_recipes: List[str]
) -> Dict[str, Any]:
    """LLMã‚’ä½¿ã£ã¦çŒ®ç«‹ã‚’ç”Ÿæˆï¼ˆAIãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰"""
    try:
        client = openai_client.get_client()
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆé£Ÿæã‚’ä¸¸æŠ•ã’ï¼‰
        prompt = f"""
ã‚ãªãŸã¯æ–™ç†ã®å°‚é–€å®¶ã§ã™ã€‚åœ¨åº«é£Ÿæã‹ã‚‰3å“æ§‹æˆã®çŒ®ç«‹ï¼ˆä¸»èœãƒ»å‰¯èœãƒ»æ±ç‰©ï¼‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ã€åœ¨åº«é£Ÿæã€‘
{', '.join(inventory_items)}

ã€çŒ®ç«‹ã‚¿ã‚¤ãƒ—ã€‘: {menu_type}

ã€åˆ¶ç´„æ¡ä»¶ã€‘
1. å„æ–™ç†ã§åŒã˜é£Ÿæã‚’ä½¿ç”¨ã—ãªã„ï¼ˆèª¿å‘³æ–™ã¯é™¤ãï¼‰
2. éå»ã®ãƒ¬ã‚·ãƒ”ã‚’é¿ã‘ã‚‹: {', '.join(excluded_recipes)}
3. åœ¨åº«é£Ÿæã‚’æœ€å¤§æ´»ç”¨ã™ã‚‹
4. å®Ÿç”¨çš„ã§ç¾å‘³ã—ã„çŒ®ç«‹ã«ã™ã‚‹

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "main_dish": {{
        "title": "ãƒ¬ã‚·ãƒ”ã‚¿ã‚¤ãƒˆãƒ«",
        "ingredients": ["é£Ÿæ1", "é£Ÿæ2", "é£Ÿæ3"]
    }},
    "side_dish": {{
        "title": "ãƒ¬ã‚·ãƒ”ã‚¿ã‚¤ãƒˆãƒ«", 
        "ingredients": ["é£Ÿæ1", "é£Ÿæ2", "é£Ÿæ3"]
    }},
    "soup": {{
        "title": "ãƒ¬ã‚·ãƒ”ã‚¿ã‚¤ãƒˆãƒ«",
        "ingredients": ["é£Ÿæ1", "é£Ÿæ2", "é£Ÿæ3"]
    }}
}}
"""

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ–™ç†ã®å°‚é–€å®¶ã§ã™ã€‚åœ¨åº«é£Ÿæã‹ã‚‰å®Ÿç”¨çš„ã§ç¾å‘³ã—ã„çŒ®ç«‹ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        content = response.choices[0].message.content
        logger.info(f"LLMå¿œç­”: {content}")
        
        # JSONè§£æï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ï¼‰
        try:
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json ... ```ï¼‰ã‚’é™¤å»
            if "```json" in content:
                start = content.find("```json") + 7
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            elif "```" in content:
                start = content.find("```") + 3
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            
            menu_data = json.loads(content)
            logger.info(f"JSONè§£æå¾Œã®çŒ®ç«‹ãƒ‡ãƒ¼ã‚¿: {menu_data}")
            return menu_data
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(f"è§£æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ: {content}")
            raise
        
    except Exception as e:
        logger.error(f"LLMçŒ®ç«‹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        raise

async def generate_menu_with_rag(
    inventory_items: List[str],
    menu_type: str,
    excluded_recipes: List[str],
    max_results: int = 3
) -> Dict[str, Any]:
    """RAGæ¤œç´¢ã‚’ä½¿ã£ã¦çŒ®ç«‹ã‚’ç”Ÿæˆï¼ˆä¼çµ±çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰"""
    try:
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
        vector_search = get_vector_search()
        vector_search._load_vector_db()  # ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿
        
        # åœ¨åº«é£Ÿæã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
        rag_query = f"{menu_type} {' '.join(inventory_items[:5])} çŒ®ç«‹ ä¸»èœ å‰¯èœ æ±ç‰©"
        logger.info(f"ğŸ” [RAGçŒ®ç«‹] æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ: '{rag_query}'")
        
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œ
        search_results = vector_search.search_similar_recipes(rag_query, k=max_results * 3)
        
        logger.info(f"ğŸ” [RAGçŒ®ç«‹] ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœ: {len(search_results)}ä»¶")
        
        # æ¤œç´¢çµæœã‹ã‚‰çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
        rag_titles = []
        for result in search_results:
            title = result.get("title", "ãƒ¬ã‚·ãƒ”")
            rag_titles.append(title)
            logger.info(f"ğŸ” [RAGçŒ®ç«‹] ç™ºè¦‹: {title}")
        
        # çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ä¸»èœãƒ»å‰¯èœãƒ»æ±ç‰©ã‚’åˆ†é¡
        main_dish_titles = [t for t in rag_titles if any(keyword in t for keyword in ["è‚‰", "é­š", "é¶", "è±š", "ç‰›", "ã‚«ãƒ¬ãƒ¼", "ãƒãƒ³ãƒãƒ¼ã‚°", "å”æšã’"])]
        side_dish_titles = [t for t in rag_titles if any(keyword in t for keyword in ["ã‚µãƒ©ãƒ€", "å’Œãˆç‰©", "ãŠã²ãŸã—", "ç‚’ã‚ç‰©", "ç…®ç‰©"])]
        soup_titles = [t for t in rag_titles if any(keyword in t for keyword in ["æ±", "ã‚¹ãƒ¼ãƒ—", "å‘³å™Œæ±", "è±šæ±"])]
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
        if not main_dish_titles:
            main_dish_titles = ["è‚‰ã˜ã‚ƒãŒ"]
        if not side_dish_titles:
            side_dish_titles = ["ã»ã†ã‚Œã‚“è‰ã®ãŠã²ãŸã—"]
        if not soup_titles:
            soup_titles = ["å‘³å™Œæ±"]
        
        # çŒ®ç«‹ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        menu_data = {
            "main_dish": {
                "title": main_dish_titles[0],
                "ingredients": inventory_items[:3]  # åœ¨åº«ã‹ã‚‰é©å½“ã«é¸æŠ
            },
            "side_dish": {
                "title": side_dish_titles[0],
                "ingredients": inventory_items[3:6] if len(inventory_items) > 3 else inventory_items[:3]
            },
            "soup": {
                "title": soup_titles[0],
                "ingredients": inventory_items[6:9] if len(inventory_items) > 6 else inventory_items[:3]
            }
        }
        
        logger.info(f"âœ… [RAGçŒ®ç«‹] ç”Ÿæˆå®Œäº†: ä¸»èœ={menu_data['main_dish']['title']}")
        return menu_data
        
    except Exception as e:
        logger.error(f"âŒ [RAGçŒ®ç«‹] ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçŒ®ç«‹
        return {
            "main_dish": {"title": "è‚‰ã˜ã‚ƒãŒ", "ingredients": inventory_items[:3]},
            "side_dish": {"title": "ã»ã†ã‚Œã‚“è‰ã®ãŠã²ãŸã—", "ingredients": inventory_items[3:6] if len(inventory_items) > 3 else inventory_items[:3]},
            "soup": {"title": "å‘³å™Œæ±", "ingredients": inventory_items[6:9] if len(inventory_items) > 6 else inventory_items[:3]}
        }

# é£Ÿæé‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨ä½¿ç”¨çŠ¶æ³è¨ˆç®—é–¢æ•°ã‚’å‰Šé™¤ï¼ˆAIãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ä¸è¦ï¼‰

# MCPãƒ„ãƒ¼ãƒ«å®šç¾©
@mcp.tool()
async def generate_menu_plan_with_history(
    inventory_items: List[str],
    excluded_recipes: List[str],
    menu_type: str = "å’Œé£Ÿ"
) -> Dict[str, Any]:
    """åœ¨åº«é£Ÿæã‹ã‚‰çŒ®ç«‹æ§‹æˆã‚’ç”Ÿæˆï¼ˆç–çµåˆè¨­è¨ˆï¼‰
    
    ğŸ¯ ä½¿ç”¨å ´é¢: åœ¨åº«é£Ÿæã‹ã‚‰éå»å±¥æ­´ã‚’è€ƒæ…®ã—ãŸçŒ®ç«‹ã‚’ææ¡ˆã™ã‚‹å ´åˆ
    
    ğŸ“‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
    - inventory_items: åœ¨åº«é£Ÿæãƒªã‚¹ãƒˆ
    - excluded_recipes: é™¤å¤–ã™ã‚‹éå»ãƒ¬ã‚·ãƒ”ã®ãƒªã‚¹ãƒˆ
    - menu_type: çŒ®ç«‹ã®ã‚¿ã‚¤ãƒ—ï¼ˆå’Œé£Ÿãƒ»æ´‹é£Ÿãƒ»ä¸­è¯ï¼‰
    
    ğŸ“‹ JSONå½¢å¼:
    {
        "success": true,
        "data": {
            "main_dish": {
                "title": "ç‰›ä¹³ã¨åµã®ãƒ•ãƒ¬ãƒ³ãƒãƒˆãƒ¼ã‚¹ãƒˆ",
                "ingredients": ["ç‰›ä¹³", "åµ", "ãƒ‘ãƒ³", "ãƒã‚¿ãƒ¼"]
            },
            "side_dish": {
                "title": "ã»ã†ã‚Œã‚“è‰ã®èƒ¡éº»å’Œãˆ",
                "ingredients": ["ã»ã†ã‚Œã‚“è‰", "èƒ¡éº»", "é†¤æ²¹"]
            },
            "soup": {
                "title": "ç™½èœã¨ãƒãƒ ã®ã‚¯ãƒªãƒ¼ãƒ ã‚¹ãƒ¼ãƒ—",
                "ingredients": ["ç™½èœ", "ãƒãƒ ", "ç‰›ä¹³", "ãƒã‚¿ãƒ¼", "å°éº¦ç²‰"]
            },
            "excluded_recipes": ["ãƒ•ãƒ¬ãƒ³ãƒãƒˆãƒ¼ã‚¹ãƒˆ", "ã‚ªãƒ ãƒ¬ãƒ„"]
        }
    }
    """
    try:
        logger.info(f"çŒ®ç«‹ç”Ÿæˆé–‹å§‹: é£Ÿæ{len(inventory_items)}ä»¶, é™¤å¤–ãƒ¬ã‚·ãƒ”{len(excluded_recipes)}ä»¶")
        
        # LLMã«ã‚ˆã‚‹çŒ®ç«‹ç”Ÿæˆï¼ˆAIãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
        menu_data = await generate_menu_with_llm(
            inventory_items, 
            menu_type, 
            excluded_recipes
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
        response_data = {
            "main_dish": menu_data.get("main_dish", {}),
            "side_dish": menu_data.get("side_dish", {}),
            "soup": menu_data.get("soup", {}),
            "excluded_recipes": excluded_recipes
        }
        
        logger.info(f"çŒ®ç«‹ç”Ÿæˆå®Œäº†: ä¸»èœ={response_data['main_dish'].get('title', 'N/A')}")
        
        return {
            "success": True,
            "data": response_data
        }
        
    except Exception as e:
        logger.error(f"çŒ®ç«‹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "success": False,
            "error": f"çŒ®ç«‹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

@mcp.tool()
async def search_menu_from_rag_with_history(
    inventory_items: List[str],
    excluded_recipes: List[str] = None,
    menu_type: str = "å’Œé£Ÿ",
    max_results: int = 3,
    token: str = None
) -> Dict[str, Any]:
    """åœ¨åº«é£Ÿæã‹ã‚‰RAGæ¤œç´¢ã§çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆè²¬ä»»åˆ†é›¢è¨­è¨ˆï¼‰
    
    ğŸ¯ ä½¿ç”¨å ´é¢: åœ¨åº«é£Ÿæã‹ã‚‰RAGæ¤œç´¢ã§ä¼çµ±çš„ãªçŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ææ¡ˆã™ã‚‹å ´åˆ
    
    ğŸ“‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
    - inventory_items: åœ¨åº«é£Ÿæãƒªã‚¹ãƒˆ
    - excluded_recipes: é™¤å¤–ã™ã‚‹éå»ãƒ¬ã‚·ãƒ”ã®ãƒªã‚¹ãƒˆ
    - menu_type: çŒ®ç«‹ã®ã‚¿ã‚¤ãƒ—ï¼ˆå’Œé£Ÿãƒ»æ´‹é£Ÿãƒ»ä¸­è¯ï¼‰
    - max_results: å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰
    
    ğŸ“‹ JSONå½¢å¼:
    {
        "success": true,
        "data": {
            "main_dish": {
                "title": "è‚‰ã˜ã‚ƒãŒ",
                "ingredients": ["è±šè‚‰", "ã˜ã‚ƒãŒã„ã‚‚", "äººå‚", "ç‰ã­ã"]
            },
            "side_dish": {
                "title": "ã»ã†ã‚Œã‚“è‰ã®ãŠã²ãŸã—",
                "ingredients": ["ã»ã†ã‚Œã‚“è‰", "é†¤æ²¹", "ã ã—"]
            },
            "soup": {
                "title": "å‘³å™Œæ±",
                "ingredients": ["å‘³å™Œ", "è±†è…", "ã‚ã‹ã‚"]
            },
            "excluded_recipes": []
        }
    }
    """
    try:
        logger.info(f"ğŸ” [RAGçŒ®ç«‹] æ¤œç´¢é–‹å§‹: é£Ÿæ{len(inventory_items)}ä»¶")
        
        # RAGæ¤œç´¢ã§çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
        menu_data = await generate_menu_with_rag(
            inventory_items, 
            menu_type, 
            excluded_recipes or [],
            max_results
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
        response_data = {
            "main_dish": menu_data.get("main_dish", {}),
            "side_dish": menu_data.get("side_dish", {}),
            "soup": menu_data.get("soup", {}),
            "excluded_recipes": excluded_recipes or []
        }
        
        logger.info(f"âœ… [RAGçŒ®ç«‹] æ¤œç´¢å®Œäº†: ä¸»èœ={response_data['main_dish'].get('title', 'N/A')}")
        
        return {
            "success": True,
            "data": response_data
        }
        
    except Exception as e:
        logger.error(f"âŒ [RAGçŒ®ç«‹] æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "success": False,
            "error": f"RAGçŒ®ç«‹æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

@mcp.tool()
async def search_recipe_from_rag(
    query: str,
    max_results: int = 5,
    category_filter: str = None,
    include_ingredients: List[str] = None,
    exclude_ingredients: List[str] = None,
    similarity_threshold: float = 0.3
) -> Dict[str, Any]:
    """RAGæ¤œç´¢ã«ã‚ˆã‚‹ãƒ¬ã‚·ãƒ”æ¤œç´¢ï¼ˆé«˜åº¦ç‰ˆï¼‰
    
    ğŸ¯ ä½¿ç”¨å ´é¢: ãƒ¬ã‚·ãƒ”ã‚¿ã‚¤ãƒˆãƒ«ã‚„é£Ÿæã‹ã‚‰é¡ä¼¼ãƒ¬ã‚·ãƒ”ã‚’æ¤œç´¢ã™ã‚‹å ´åˆ
    
    ğŸ“‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
    - query: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆä¾‹: "ç‰›ä¹³ã¨åµ", "ãƒ•ãƒ¬ãƒ³ãƒãƒˆãƒ¼ã‚¹ãƒˆ", "è‚‰ã˜ã‚ƒãŒ"ï¼‰
    - max_results: å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
    - category_filter: ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ï¼ˆä¾‹: "ä¸»èœ", "å‰¯èœ", "æ±ç‰©"ï¼‰
    - include_ingredients: å«ã‚ã‚‹é£Ÿæãƒªã‚¹ãƒˆï¼ˆä¾‹: ["åµ", "ç‰›ä¹³"]ï¼‰
    - exclude_ingredients: é™¤å¤–ã™ã‚‹é£Ÿæãƒªã‚¹ãƒˆï¼ˆä¾‹: ["è‚‰", "é­š"]ï¼‰
    - similarity_threshold: é¡ä¼¼åº¦é–¾å€¤ï¼ˆ0.0-1.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.3ï¼‰
    
    ğŸ“‹ JSONå½¢å¼:
    {
        "success": true,
        "data": {
            "query": "ç‰›ä¹³ã¨åµ",
            "filters": {
                "category": "ä¸»èœ",
                "include_ingredients": ["åµ", "ç‰›ä¹³"],
                "exclude_ingredients": ["è‚‰"],
                "similarity_threshold": 0.3
            },
            "total_found": 3,
            "recipes": [
                {
                    "rank": 1,
                    "title": "ç‰›ä¹³ã¨åµã®ãƒ•ãƒ¬ãƒ³ãƒãƒˆãƒ¼ã‚¹ãƒˆ",
                    "category": "ä¸»èœ",
                    "main_ingredients": "åµ",
                    "similarity_score": 0.1234,
                    "text_preview": "ç‰›ä¹³ã¨åµã®ãƒ•ãƒ¬ãƒ³ãƒãƒˆãƒ¼ã‚¹ãƒˆ ç‰›ä¹³ åµ ãƒ‘ãƒ³ ãƒã‚¿ãƒ¼..."
                }
            ]
        }
    }
    """
    try:
        logger.info(f"RAGæ¤œç´¢é–‹å§‹: '{query}' (æœ€å¤§{max_results}ä»¶)")
        logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿: ã‚«ãƒ†ã‚´ãƒª={category_filter}, å«ã‚ã‚‹é£Ÿæ={include_ingredients}, é™¤å¤–é£Ÿæ={exclude_ingredients}, é–¾å€¤={similarity_threshold}")
        
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
        vector_search = get_vector_search()
        
        # ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µï¼ˆå«ã‚ã‚‹é£ŸæãŒã‚ã‚‹å ´åˆï¼‰
        enhanced_query = query
        if include_ingredients:
            ingredient_query = " ".join(include_ingredients)
            enhanced_query = f"{query} {ingredient_query}"
            logger.info(f"ã‚¯ã‚¨ãƒªæ‹¡å¼µ: '{query}' â†’ '{enhanced_query}'")
        
        # æ¤œç´¢æˆ¦ç•¥ã®å‹•çš„èª¿æ•´
        if include_ingredients or exclude_ingredients:
            search_k = max(max_results * 5, 50)  # é£Ÿæãƒ•ã‚£ãƒ«ã‚¿ãŒã‚ã‚‹å ´åˆã¯å¤šã‚ã«
        else:
            search_k = max(max_results * 2, 15)  # é€šå¸¸ã¯å°‘ãªã‚ã«
        
        logger.info(f"æ¤œç´¢æˆ¦ç•¥: k={search_k} (ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶: å«ã‚ã‚‹={bool(include_ingredients)}, é™¤å¤–={bool(exclude_ingredients)})")
        
        # é¡ä¼¼ãƒ¬ã‚·ãƒ”ã‚’æ¤œç´¢
        results = vector_search.search_similar_recipes(enhanced_query, k=search_k)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
        filtered_results = []
        for result in results:
            # é¡ä¼¼åº¦é–¾å€¤ãƒã‚§ãƒƒã‚¯
            if result["similarity_score"] < similarity_threshold:
                continue
                
            # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿
            if category_filter and result["category"] != category_filter:
                continue
                
            # å«ã‚ã‚‹é£Ÿæãƒã‚§ãƒƒã‚¯ï¼ˆæŸ”è»ŸåŒ–ï¼‰
            if include_ingredients:
                main_ingredients = result["main_ingredients"].lower()
                text_preview = result["text_preview"].lower()
                
                # main_ingredientsã¾ãŸã¯text_previewã«é£ŸæãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                ingredient_found = False
                for ingredient in include_ingredients:
                    ingredient_lower = ingredient.lower()
                    if (ingredient_lower in main_ingredients or 
                        ingredient_lower in text_preview):
                        ingredient_found = True
                        break
                
                if not ingredient_found:
                    continue
                    
            # é™¤å¤–é£Ÿæãƒã‚§ãƒƒã‚¯ï¼ˆæŸ”è»ŸåŒ–ï¼‰
            if exclude_ingredients:
                main_ingredients = result["main_ingredients"].lower()
                text_preview = result["text_preview"].lower()
                
                # main_ingredientsã¾ãŸã¯text_previewã«é™¤å¤–é£ŸæãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                excluded_found = False
                for ingredient in exclude_ingredients:
                    ingredient_lower = ingredient.lower()
                    if (ingredient_lower in main_ingredients or 
                        ingredient_lower in text_preview):
                        excluded_found = True
                        break
                
                if excluded_found:
                    continue
                    
            # ãƒ•ã‚£ãƒ«ã‚¿ã‚’é€šéã—ãŸçµæœã‚’è¿½åŠ 
            filtered_results.append(result)
            
            # æœ€å¤§ä»¶æ•°ã«é”ã—ãŸã‚‰çµ‚äº†
            if len(filtered_results) >= max_results:
                break
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨­å®š
        for i, result in enumerate(filtered_results, 1):
            result["rank"] = i
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
        response_data = {
            "query": query,
            "filters": {
                "category": category_filter,
                "include_ingredients": include_ingredients,
                "exclude_ingredients": exclude_ingredients,
                "similarity_threshold": similarity_threshold
            },
            "total_found": len(filtered_results),
            "recipes": filtered_results
        }
        
        logger.info(f"RAGæ¤œç´¢å®Œäº†: {len(filtered_results)}ä»¶ã®ãƒ¬ã‚·ãƒ”ã‚’ç™ºè¦‹ï¼ˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œï¼‰")
        
        return {
            "success": True,
            "data": response_data
        }
        
    except Exception as e:
        logger.error(f"RAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "success": False,
            "error": f"RAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

@mcp.tool()
async def search_recipe_from_web(
    menu_titles: List[str],
    max_results: int = 3
) -> Dict[str, Any]:
    """Webæ¤œç´¢ã«ã‚ˆã‚‹ãƒ¬ã‚·ãƒ”æ¤œç´¢ï¼ˆè²¬ä»»åˆ†é›¢è¨­è¨ˆï¼‰
    
    ğŸ¯ ä½¿ç”¨å ´é¢: çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ãƒ¬ã‚·ãƒ”URLã‚’å–å¾—ã™ã‚‹å ´åˆ
    
    ğŸ“‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
    - menu_titles: çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã®é…åˆ—ï¼ˆä¾‹: ["è‚‰ã˜ã‚ƒãŒ", "ã»ã†ã‚Œã‚“è‰ã®ãŠã²ãŸã—", "å‘³å™Œæ±"]ï¼‰
    - max_results: å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰
    
    ğŸ“‹ JSONå½¢å¼:
    {
        "success": true,
        "data": {
            "query": "è‚‰ã˜ã‚ƒãŒ ä½œã‚Šæ–¹",
            "total_found": 3,
            "recipes": [
                {
                    "title": "åŸºæœ¬ã®è‚‰ã˜ã‚ƒãŒ",
                    "url": "https://cookpad.com/recipe/123456",
                    "source": "ã‚¯ãƒƒã‚¯ãƒ‘ãƒƒãƒ‰",
                    "ingredients": ["ã˜ã‚ƒãŒã„ã‚‚", "ç‰ã­ã", "ç‰›è‚‰", "ã ã—æ±"],
                    "instructions": "1. ã˜ã‚ƒãŒã„ã‚‚ã‚’ä¸€å£å¤§ã«åˆ‡ã‚‹...",
                    "cooking_time": "30åˆ†",
                    "servings": "4äººåˆ†"
                }
            ]
        }
    }
    """
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼
        if not menu_titles:
            return {
                "success": False,
                "error": "menu_titlesãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"
            }
        
        # çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
        queries = [f"{title} ä½œã‚Šæ–¹" for title in menu_titles]
        
        logger.info(f"ğŸ” [Webæ¤œç´¢] é–‹å§‹: {len(queries)}å€‹ã®çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ« (æœ€å¤§{max_results}ä»¶/ã‚¿ã‚¤ãƒˆãƒ«)")
        
        # Perplexity API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        client = get_perplexity_client()
        
        # å…¨ã‚¯ã‚¨ãƒªã®çµæœã‚’æ ¼ç´
        all_recipes = []
        
        # å„çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã§å€‹åˆ¥ã«æ¤œç´¢
        for i, (menu_title, single_query) in enumerate(zip(menu_titles, queries)):
            logger.info(f"ğŸ” [Webæ¤œç´¢] {i+1}/{len(queries)}: '{menu_title}' -> '{single_query}'")
            
            try:
                # ãƒ¬ã‚·ãƒ”æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†ä»˜ãï¼‰
                import asyncio
                recipes = await asyncio.wait_for(
                    asyncio.to_thread(client.search_recipe, single_query, max_results=max_results),
                    timeout=30.0  # 30ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )
                
                # çµæœã«çŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«æƒ…å ±ã‚’è¿½åŠ 
                for recipe in recipes:
                    recipe_data = {
                        "menu_title": menu_title,
                        "query": single_query,
                        "title": recipe.title,
                        "url": recipe.url,
                        "source": recipe.source,
                        "ingredients": recipe.ingredients,
                        "instructions": recipe.instructions,
                        "cooking_time": recipe.cooking_time,
                        "servings": recipe.servings,
                        "snippet": recipe.snippet
                    }
                    all_recipes.append(recipe_data)
                
                logger.info(f"âœ… [Webæ¤œç´¢] {i+1} å®Œäº†: {len(recipes)}ä»¶ã®ãƒ¬ã‚·ãƒ”ã‚’ç™ºè¦‹")
                
            except asyncio.TimeoutError:
                logger.warning(f"âš ï¸ [Webæ¤œç´¢] {i+1} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: '{menu_title}' (30ç§’)")
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸçŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã®çµæœã‚’è¿½åŠ 
                all_recipes.append({
                    "menu_title": menu_title,
                    "query": single_query,
                    "title": f"{menu_title} (æ¤œç´¢ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ)",
                    "url": "",
                    "source": "ã‚¨ãƒ©ãƒ¼",
                    "ingredients": [],
                    "instructions": "æ¤œç´¢ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚",
                    "cooking_time": "",
                    "servings": "",
                    "snippet": ""
                })
            except Exception as e:
                logger.error(f"âŒ [Webæ¤œç´¢] {i+1} ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸçŒ®ç«‹ã‚¿ã‚¤ãƒˆãƒ«ã®çµæœã‚’è¿½åŠ 
                all_recipes.append({
                    "menu_title": menu_title,
                    "query": single_query,
                    "title": f"{menu_title} (æ¤œç´¢ã‚¨ãƒ©ãƒ¼)",
                    "url": "",
                    "source": "ã‚¨ãƒ©ãƒ¼",
                    "ingredients": [],
                    "instructions": f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "cooking_time": "",
                    "servings": "",
                    "snippet": ""
                })
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
        response_data = {
            "menu_titles": menu_titles,
            "queries": queries,
            "total_titles": len(menu_titles),
            "total_found": len(all_recipes),
            "recipes": all_recipes
        }
        
        logger.info(f"âœ… [Webæ¤œç´¢] å®Œäº†: {len(all_recipes)}ä»¶ã®ãƒ¬ã‚·ãƒ”ã‚’ç™ºè¦‹")
        
        return {
            "success": True,
            "data": response_data
        }
        
    except Exception as e:
        logger.error(f"Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "success": False,
            "error": f"Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

# RAGæ¤œç´¢å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ - ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’ä½¿ç”¨
        if rag_search and inventory_items:
            logger.info(f"ğŸ” [ä¸¦åˆ—æç¤º] RAGæ¤œç´¢é–‹å§‹: {inventory_items}")
            
            try:
                # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
                vector_search = get_vector_search()
                vector_search._load_vector_db()  # ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿
                
                # åœ¨åº«é£Ÿæã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
                rag_query = f"{' '.join(inventory_items)} ãƒ¬ã‚·ãƒ”"
                logger.info(f"ğŸ” [RAGæ¤œç´¢] æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ: '{rag_query}'")
                logger.info(f"ğŸ” [RAGæ¤œç´¢] æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: k={max_results * 3}, inventory_items={inventory_items[:5]}...")
                
                # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œ
                search_results = vector_search.search_similar_recipes(rag_query, k=max_results * 3)
                
                logger.info(f"ğŸ” [RAGæ¤œç´¢] ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœ: {len(search_results)}ä»¶")
                if search_results:
                    logger.info(f"ğŸ” [RAGæ¤œç´¢] æœ€åˆã®3ä»¶ã®ã‚¿ã‚¤ãƒˆãƒ«: {[result.get('title', 'N/A') for result in search_results[:3]]}")
                
                rag_recipes = []
                if search_results:
                    rag_titles = []
                    for result in search_results:
                        title = result.get("title", "ãƒ¬ã‚·ãƒ”")
                        rag_titles.append(title)
                    
                    # RAGæ¤œç´¢ã§å–å¾—ã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã«Webæ¤œç´¢ã‚’å®Ÿè¡Œ
                    if rag_titles:
                        logger.info(f"ğŸ” [ä¸¦åˆ—æç¤º] RAGã‚¿ã‚¤ãƒˆãƒ«ã‚’Webæ¤œç´¢: {rag_titles}")
                        for title in rag_titles:
                            try:
                                web_recipes = await asyncio.wait_for(
                                    asyncio.to_thread(perplexity_client.search_recipe, f"{title} ä½œã‚Šæ–¹", max_results=max_results),
                                    timeout=30.0
                                )
                                
                                for recipe in web_recipes:
                                    recipe_data = {
                                        "title": recipe.title,
                                        "url": recipe.url,
                                        "source": recipe.source,
                                        "ingredients": recipe.ingredients,
                                        "instructions": recipe.instructions,
                                        "cooking_time": recipe.cooking_time,
                                        "servings": recipe.servings,
                                        "snippet": recipe.snippet
                                    }
                                    rag_recipes.append(recipe_data)
                                
                                logger.info(f"âœ… [ä¸¦åˆ—æç¤º] RAGã‚¿ã‚¤ãƒˆãƒ« '{title}' ã®Webæ¤œç´¢å®Œäº†: {len(web_recipes)}ä»¶")
                                
                            except asyncio.TimeoutError:
                                logger.warning(f"âš ï¸ [ä¸¦åˆ—æç¤º] RAGã‚¿ã‚¤ãƒˆãƒ« '{title}' ã®Webæ¤œç´¢ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                            except Exception as e:
                                logger.error(f"âŒ [ä¸¦åˆ—æç¤º] RAGã‚¿ã‚¤ãƒˆãƒ« '{title}' ã®Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                
                results["rag_recipes"] = rag_recipes
                logger.info(f"âœ… [ä¸¦åˆ—æç¤º] RAGæ¤œç´¢å®Œäº†: {len(rag_recipes)}ä»¶")
                
            except Exception as e:
                logger.error(f"âŒ [ä¸¦åˆ—æç¤º] RAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                results["rag_recipes"] = []

@mcp.tool()
async def search_recipe_integrated(
    query: str,
    max_results: int = 5,
    rag_weight: float = 0.6,
    web_weight: float = 0.4
) -> Dict[str, Any]:
    """çµ±åˆãƒ¬ã‚·ãƒ”æ¤œç´¢ï¼ˆRAGæ¤œç´¢ + Webæ¤œç´¢ï¼‰
    
    ğŸ¯ ä½¿ç”¨å ´é¢: RAGæ¤œç´¢ã¨Webæ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ã¦æœ€é©ãªãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã™ã‚‹å ´åˆ
    
    ğŸ“‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
    - query: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆä¾‹: "è‚‰ã˜ã‚ƒãŒ ä½œã‚Šæ–¹", "ãƒ•ãƒ¬ãƒ³ãƒãƒˆãƒ¼ã‚¹ãƒˆ ãƒ¬ã‚·ãƒ”"ï¼‰
    - max_results: å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
    - rag_weight: RAGæ¤œç´¢çµæœã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.6ï¼‰
    - web_weight: Webæ¤œç´¢çµæœã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.4ï¼‰
    
    ğŸ“‹ JSONå½¢å¼:
    {
        "success": true,
        "data": {
            "query": "è‚‰ã˜ã‚ƒãŒ ä½œã‚Šæ–¹",
            "total_found": 5,
            "rag_results": 3,
            "web_results": 2,
            "recipes": [
                {
                    "rank": 1,
                    "title": "åŸºæœ¬ã®è‚‰ã˜ã‚ƒãŒ",
                    "source": "rag",
                    "similarity_score": 0.85,
                    "url": null,
                    "ingredients": ["ã˜ã‚ƒãŒã„ã‚‚", "ç‰ã­ã", "ç‰›è‚‰", "ã ã—æ±"],
                    "cooking_time": "30åˆ†",
                    "servings": "4äººåˆ†"
                }
            ]
        }
    }
    """
    try:
        logger.info(f"çµ±åˆæ¤œç´¢é–‹å§‹: '{query}' (æœ€å¤§{max_results}ä»¶, RAGé‡ã¿:{rag_weight}, Webé‡ã¿:{web_weight})")
        
        # 1. RAGæ¤œç´¢å®Ÿè¡Œ
        rag_results = await search_recipe_from_rag(
            query=query,
            max_results=max_results * 2,  # å¤šã‚ã«å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨
            similarity_threshold=0.2
        )
        
        # 2. Webæ¤œç´¢å®Ÿè¡Œ
        web_results = await search_recipe_from_web(
            query=query,
            max_results=max_results * 2  # å¤šã‚ã«å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨
        )
        
        # 3. çµæœã®çµ±åˆ
        integrated_recipes = []
        
        # RAGçµæœã®å‡¦ç†
        if rag_results.get("success") and rag_results.get("data", {}).get("recipes"):
            for recipe in rag_results["data"]["recipes"]:
                integrated_recipe = {
                    "title": recipe.get("title", ""),
                    "source": "rag",
                    "similarity_score": recipe.get("similarity_score", 0.0),
                    "url": None,
                    "ingredients": recipe.get("main_ingredients", "").split(", ") if recipe.get("main_ingredients") else [],
                    "cooking_time": "è¨˜è¼‰ãªã—",
                    "servings": "è¨˜è¼‰ãªã—",
                    "category": recipe.get("category", ""),
                    "text_preview": recipe.get("text_preview", "")
                }
                integrated_recipes.append(integrated_recipe)
        
        # Webçµæœã®å‡¦ç†
        if web_results.get("success") and web_results.get("data", {}).get("recipes"):
            for recipe in web_results["data"]["recipes"]:
                integrated_recipe = {
                    "title": recipe.get("title", ""),
                    "source": "web",
                    "similarity_score": 0.0,  # Webæ¤œç´¢ã«ã¯é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãŒãªã„
                    "url": recipe.get("url", ""),
                    "ingredients": recipe.get("ingredients", []),
                    "cooking_time": recipe.get("cooking_time", "è¨˜è¼‰ãªã—"),
                    "servings": recipe.get("servings", "è¨˜è¼‰ãªã—"),
                    "category": "",
                    "text_preview": recipe.get("snippet", "")
                }
                integrated_recipes.append(integrated_recipe)
        
        # 4. é‡è¤‡é™¤å»ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼åº¦ã§åˆ¤å®šï¼‰
        unique_recipes = []
        for recipe in integrated_recipes:
            is_duplicate = False
            for existing in unique_recipes:
                # ã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’ç°¡æ˜“è¨ˆç®—
                title_similarity = calculate_title_similarity(recipe["title"], existing["title"])
                if title_similarity > 0.8:  # 80%ä»¥ä¸Šé¡ä¼¼ã—ã¦ã„ã‚‹å ´åˆã¯é‡è¤‡ã¨ã¿ãªã™
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_recipes.append(recipe)
        
        # 5. ç°¡å˜ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆRAGã‚¹ã‚³ã‚¢ + Webé †ä½ï¼‰
        for i, recipe in enumerate(unique_recipes):
            if recipe["source"] == "rag":
                # RAGçµæœ: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã‚’é‡ã¿ä»˜ã‘
                recipe["rank_score"] = recipe["similarity_score"] * rag_weight
            else:
                # Webçµæœ: é †ä½ã‚’é‡ã¿ä»˜ã‘ï¼ˆä¸Šä½ã»ã©é«˜ã‚¹ã‚³ã‚¢ï¼‰
                web_rank = i + 1
                recipe["rank_score"] = (1.0 / web_rank) * web_weight
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        unique_recipes.sort(key=lambda x: x["rank_score"], reverse=True)
        
        # æœ€å¤§ä»¶æ•°ã«åˆ¶é™
        final_recipes = unique_recipes[:max_results]
        
        # ãƒ©ãƒ³ã‚¯ã‚’å†è¨­å®š
        for i, recipe in enumerate(final_recipes, 1):
            recipe["rank"] = i
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚³ã‚¢ã¯å†…éƒ¨ç”¨ãªã®ã§å‰Šé™¤
            if "rank_score" in recipe:
                del recipe["rank_score"]
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
        response_data = {
            "query": query,
            "total_found": len(final_recipes),
            "rag_results": len([r for r in final_recipes if r["source"] == "rag"]),
            "web_results": len([r for r in final_recipes if r["source"] == "web"]),
            "recipes": final_recipes
        }
        
        logger.info(f"çµ±åˆæ¤œç´¢å®Œäº†: {len(final_recipes)}ä»¶ã®ãƒ¬ã‚·ãƒ”ã‚’ç™ºè¦‹ (RAG:{response_data['rag_results']}ä»¶, Web:{response_data['web_results']}ä»¶)")
        
        return {
            "success": True,
            "data": response_data
        }
        
    except Exception as e:
        logger.error(f"çµ±åˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "success": False,
            "error": f"çµ±åˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }


def calculate_title_similarity(title1: str, title2: str) -> float:
    """ã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    if not title1 or not title2:
        return 0.0
    
    # æ–‡å­—åˆ—ã‚’å°æ–‡å­—ã«å¤‰æ›
    t1 = title1.lower()
    t2 = title2.lower()
    
    # å®Œå…¨ä¸€è‡´
    if t1 == t2:
        return 1.0
    
    # éƒ¨åˆ†ä¸€è‡´
    if t1 in t2 or t2 in t1:
        return 0.8
    
    # å˜èªãƒ¬ãƒ™ãƒ«ã§ã®ä¸€è‡´
    words1 = set(t1.split())
    words2 = set(t2.split())
    
    if not words1 or not words2:
        return 0.0
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0.0

if __name__ == "__main__":
    print("ğŸš€ Recipe MCP Server (stdio transport) starting...")
    print("ğŸ“¡ Available tools: generate_menu_plan_with_history, search_menu_from_rag_with_history, search_recipe_from_rag, search_recipe_from_web, search_recipe_integrated")
    print("ğŸ”— Transport: stdio")
    print("Press Ctrl+C to stop the server")
    
    # stdioãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆã§èµ·å‹•
    mcp.run(transport="stdio")
