from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from openai import OpenAI
import os
from typing import Optional
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

app = FastAPI(title="Morizo AI", description="Smart Pantry AI Agent")

# OpenAI APIè¨­å®š
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
model_name = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
print(f"ğŸš€ Morizo AI Server starting...")
print(f"ğŸ“‹ Using OpenAI Model: {model_name}")
print(f"ğŸ”‘ API Key configured: {'Yes' if os.getenv('OPENAI_API_KEY') else 'No'}")

class ChatRequest(BaseModel):
    message: str
    user_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    success: bool
    model_used: str

@app.get("/")
async def root():
    return {"message": "Morizo AI is running!"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "Morizo AI"}

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’LLMã«é€ä¿¡ã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
    """
    try:
        if not os.getenv("OPENAI_API_KEY"):
            raise HTTPException(status_code=500, detail="OpenAI API key not configured")
        
        # OpenAI APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        model_name = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯gpt-4o-mini
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯Morizoã¨ã„ã†åå‰ã®ã‚¹ãƒãƒ¼ãƒˆãƒ‘ãƒ³ãƒˆãƒªãƒ¼ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é£Ÿæç®¡ç†ã¨ãƒ¬ã‚·ãƒ”ææ¡ˆã‚’æ‰‹ä¼ã„ã¾ã™ã€‚æ—¥æœ¬èªã§è¦ªã—ã¿ã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": request.message}
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        ai_response = response.choices[0].message.content
        actual_model = response.model  # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
        
        return ChatResponse(
            response=ai_response,
            success=True,
            model_used=actual_model
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI processing error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
